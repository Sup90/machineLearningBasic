{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model save / load\n",
    "\n",
    "### 생성한 모델을 disk 에 저장하고 복원\n",
    "\n",
    "- model 의 architecture 저장 : json, yaml format  \n",
    "\n",
    "- model 의 weigth 저장 : h5 file format  \n",
    "\n",
    "- hdf5(Hierarchical Data Format version 5)는 대용량 데이터를 저장하기 위한 파일 포맷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2210 - acc: 0.9343 - val_loss: 0.0654 - val_acc: 0.9798\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0654 - acc: 0.9798\n",
      "0.06536953851068393\n",
      "0.9798\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train[:, :, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "\n",
    "# LeNet\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=5, padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"valid\"))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=5, padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(84))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=1, validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lenet.json\", \"w\") as json_file:\n",
    "    json_file.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight 만 save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"lenet_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lenet_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Load\n",
    "\n",
    "- architecture load + weight load + compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open(\"lenet.json\", \"r\")\n",
    "read_model = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(read_model)\n",
    "loaded_model.load_weights(\"lenet_weight.h5\")\n",
    "\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0654 - acc: 0.9798\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('lenet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 84us/sample - loss: 0.0654 - acc: 0.9798\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1072620e-06, 5.0682735e-07, 8.9254841e-05, ..., 9.9979192e-01,\n",
       "        1.9974200e-07, 2.6895765e-05],\n",
       "       [9.4027564e-06, 9.4089955e-05, 9.9982280e-01, ..., 3.1291747e-09,\n",
       "        2.6771559e-05, 8.7529595e-11],\n",
       "       [1.8905029e-04, 9.9608934e-01, 9.0959930e-04, ..., 4.1674782e-04,\n",
       "        1.0186188e-03, 1.3086006e-04],\n",
       "       ...,\n",
       "       [3.1842017e-08, 1.1226711e-06, 7.0094977e-08, ..., 2.0878047e-06,\n",
       "        2.1368935e-06, 1.3689404e-04],\n",
       "       [6.0698005e-07, 5.6845039e-08, 4.9737313e-08, ..., 1.3568047e-08,\n",
       "        6.8907486e-03, 5.3856746e-07],\n",
       "       [3.3959093e-06, 8.5748075e-10, 2.7060403e-06, ..., 2.0614845e-11,\n",
       "        1.2906453e-06, 1.0645661e-09]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.98"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(y_predict, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_classes(X_test[:1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 : Model 을 yaml file 로 저장하고 복원 후 weight load 및 compile 및 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
